---
title: "Master Thesis Data Preparation"
author: "Leon Reiß"
date: "2024-03-23"
output: html_document
---

## Sources of Data

The data was not collected by the author himself. We have a dataset for the spatio-temporal analysis, which comes from *https://citibikenyc.com/system-data* and a weather dataset from *https://github.com/leokassio/weather-underground-data/blob/master/new-york-2015.csv* (weather underground). both datasets refer to the years 2015 and 2016.

```{r setup, include=FALSE}

#Loading necessary packages
library(tidyverse)
library(dplyr)

#Cleaning the environment
rm(list = ls())

```

## Spatio-temporal Dataset CitiBike Trip Data

```{r Loading and merging the folders pfor spatio-temporal data}
#Creating a main path to the data folders
main_path_2016 <- '/Users/leonreiss/Desktop/2016-citibike-tripdata'

#Create list of folders for every month
folders <- list.files(main_path_2016, full.names = TRUE)

#Read data from all montly folders and merge them
all_data <- folders %>%
  map(~list.files(.x, full.names = TRUE, pattern = "\\.csv$")) %>% 
  map_df(~read_csv(.x))

#write result in csv
write_csv(all_data, file.path(main_path_2016, 'all_data'))
str(all_data)

##Note: There are empty columns with the same name as filled columns, only written in capital letters. It has to be checked, wether these column contain any values.

#List of columns to be checked
columns_to_check <- c("Trip Duration", "Start Time", "Stop Time", "Start Station ID", 
                        "Start Station Name", "Start Station Latitude", "Start Station Longitude", 
                        "End Station ID", "End Station Name", "End Station Latitude", 
                        "End Station Longitude", "Bike ID", "User Type", "Birth Year", "Gender")

# Check if they contain only empty values
for (column_name in columns_to_check) {
  na_count <- sum(is.na(all_data[[column_name]]))
  message(column_name, " hat ", na_count, " leere Werte (NA).")
}

# List of columns to check for presence of values
columns_to_check <- c("Trip Duration", "Start Time", "Stop Time", "Start Station ID", 
                      "Start Station Name", "Start Station Latitude", "Start Station Longitude", 
                      "End Station ID", "End Station Name", "End Station Latitude", 
                      "End Station Longitude", "Bike ID", "User Type", "Birth Year", "Gender")


```

## Results of columns_to_check
Trip Duration has 10262649 empty values (NA).
Start Time has 10262649 empty values (NA).
Stop Time has 10262649 empty values (NA).
Start Station ID has 10262649 empty values (NA).
Start Station Name has 10262649 empty values (NA).
Start Station Latitude has 10262649 empty values (NA).
Start Station Longitude has 10262649 empty values (NA). 
End Station ID has 10262649 empty values (NA).
End Station Name has 10262649 empty values (NA).
End Station Latitude has 10262649 empty values (NA).
End Station Longitude has 10262649 empty values (NA).
Bike ID has 10262649 empty values (NA).
User Type has 10298520 empty values (NA).
Birth Year has 10566167 empty values (NA).
Gender has 10262649 empty values (NA).


``` {r Further investigation for missing values}

# Initialize a vector to store dates from "Start Time" where data is present
dates_with_data <- c()

# Loop through the specified columns
for (column in columns_to_check) {
  # Check if there are any non-NA (non-empty) values in the column
  if (any(!is.na(all_data[[column]]))) {
    # If the column is "Start Time", extract and store the dates
    if (column == "Start Time") {
      # Attempt to convert "Start Time" to Date format (adjust format as needed)
      start_dates <- as.Date(all_data[["Start Time"]], format = "%m/%d/%Y %H:%M:%S")
      
      # Remove NA values from conversion attempt
      valid_dates <- na.omit(start_dates)
      
      # Add unique dates to the list
      dates_with_data <- unique(c(dates_with_data, valid_dates))
    }
  }
}

# Print the dates where data is present
print(dates_with_data)

# Convert into right format
dates_with_data_readable <- as.Date(dates_with_data, origin = "1970-01-01")

#Print of result
print(dates_with_data_readable)


##Note: it seems that the data starting from the 1st of october until the end of the year is saved in the columns using capital letters. A visual investigation of the corresponding tables confirms this assumption.


```

## Loading and merging all data starting from october to end of the year

``` {r Loading and merging from october 16 to december 16}

# Set the path to the directory containing the CSV files
exception_path <- "/Users/leonreiss/Desktop/Exceptions for 2016" # Ersetze dies durch deinen tatsächlichen Pfad

# List all CSV files in the directory
folders_exceptions <- list.files(exception_path, full.names = TRUE)

#Read data from all montly folders and merge them
exception_2016 <- folders_exceptions %>%
  map(~list.files(.x, full.names = TRUE, pattern = "\\.csv$")) %>% 
  map_df(~read_csv(.x))


str(exception_2016)
str(all_data)

# first definition of scheme
renaming_schema <- list(
  "Trip Duration" = "tripduration",
  "Start Time" = "starttime",
  "Stop Time" = "stoptime",
  "Start Station ID" = "start station id",
  "Start Station Name" = "start station name",
  "Start Station Latitude" = "start station latitude",
  "Start Station Longitude" = "start station longitude",
  "End Station ID" = "end station id",
  "End Station Name" = "end station name",
  "End Station Latitude" = "end station latitude",
  "End Station Longitude" = "end station longitude",
  "Bike ID" = "bikeid",
  "User Type" = "usertype",
  "Birth Year" = "birth year",
  "Gender" = "gender"
)

# usage of scheme to convert table columns

for (old_name in names(renaming_schema)) {
  new_name <- renaming_schema[[old_name]]
  
  # check if old column exists
  if (old_name %in% names(exception_2016)) {
    #copy of data from old name to new column
   exception_2016[[new_name]] <- exception_2016[[old_name]]
    
    if (old_name == "Start Time" || old_name == "Stop Time") {
      exception_2016[[new_name]] <- as.character(exception_2016[[new_name]])
    }
    
    # removing the old column
   exception_2016[[old_name]] <- NULL
  }
}

# check
str(exception_2016)
all_data

```

''Merging together the data from all_data and exception_2016 (october bis december 2016)
``` {r Merging of 2016}

# Merge exception_2016 with all_data
combined_data <- bind_rows(all_data, exception_2016)

# check
head(combined_data)

#Note: everything is working now
```


## Now loading the data for 2015

``` {r loading and merging the 2015 dataset}

main_path_2015 <- '/Users/leonreiss/Desktop/DATA THESIS/Spatio temporal/2015-citibike-tripdata'

# List of folders for 2015
folders_2015 <- list.files(main_path_2015, full.names = TRUE)

# Alle CSV-Dateien aus allen Monatsordnern für 2016 lesen und zu all_data hinzufügen
all_data_2015 <- folders_2015 %>%
  map(~list.files(.x, full.names = TRUE, pattern = "\\.csv$")) %>% 
  map_df(~read_csv(.x))

all_data_2015
all_data_2015$starttime

#RawBikeData <- bind_rows(all_data_2015, combined_data)
#head(RawBikeData, 200)

# Speichere den Dataframe 'RawBikeData' als CSV-Datei
#write.csv(RawBikeData, "RawBikeData.csv", row.names = FALSE)
write.csv(all_data_2015, "RawBikeData_2015.csv", row.names = FALSE)

#########Note: Final dataset for spatio-temporal Analysis is RawBikeData
# Saving of Dataframe 'RawBikeData' as CSV-file
#write.csv(RawBikeData, "/Users/leonreiss/Desktop/RawBikeData.csv", row.names = FALSE)

```


##Checking the date format

``` {r Investigation of 2015 raw citibike dataset}
#all_data_2015
all_data_2015
#Converting to the date format
#all_data_2015$starttime <- as.Date(all_data_2015$starttime, format = "%m/%d/%Y %H:%M")
#all_data_2015$stoptime <- as.Date(all_data_2015$stoptime, format = "%m/%d/%Y %H:%M")
##Note: Not working due to the fact that minutes and hours are getting lost!

################################
# Check if the format of each time in 'starttime' and 'stoptime' matches the pattern "m/d/yyyy h:mm"
check_time_format <- function(time_vector) {
  # Define the regular expression pattern for the date and time format
  pattern <- "^\\d{1,2}/\\d{1,2}/\\d{4} \\d{1,2}:\\d{2}$"
  
  # Check if each time matches the pattern
  correct_format <- grepl(pattern, time_vector)
  
  # Return whether all times match the pattern
  all(correct_format)
}

# Apply the function to 'starttime' and 'stoptime' columns of 'all_data_2015'
all_starttime_correct <- check_time_format(all_data_2015$starttime)
all_stoptime_correct <- check_time_format(all_data_2015$stoptime)

# Output the results
print(paste("All 'starttime' entries have correct format:", all_starttime_correct))
print(paste("All 'stoptime' entries have correct format:", all_stoptime_correct))
#Result: both are FALSE

#####################Now Implementing a unified format for starttime and stoptime

# Define a function to standardize the time format to ensure two digits for hours and minutes
standardize_time_format <- function(time_vector) {
  # Use 'strptime' and 'format' to convert and ensure times have two digits for hours and minutes
  formatted_times <- format(strptime(time_vector, "%m/%d/%Y %H:%M"), "%m/%d/%Y %H:%M")
  # Replace single-digit hours and minutes with two digits
  formatted_times <- sub(" (\\d):", " 0\\1:", formatted_times) # For hours
  formatted_times <- sub(":(\\d)$", ":0\\1", formatted_times)  # For minutes
  return(formatted_times)
}

# Apply the formatting function to 'starttime' and 'stoptime'
all_data_2015$starttime <- standardize_time_format(all_data_2015$starttime)
all_data_2015$stoptime <- standardize_time_format(all_data_2015$stoptime)

# Re-check the formats after standardization
all_starttime_correct_after <- check_time_format(all_data_2015$starttime)
all_stoptime_correct_after <- check_time_format(all_data_2015$stoptime)

# Output the results
print(paste("All 'starttime' entries have correct format after standardization:", all_starttime_correct_after))
print(paste("All 'stoptime' entries have correct format after standardization:", all_stoptime_correct_after))


all_data_2015$stoptime
#Result: Standardization successful!
```

##Checking the number of rows
After the first data pre-processing step in the model of Chai et al. (2018), I found that after merging the different csv files (sotred in the lists first) are missing months. After investigation, mostly values in January and October are retained
``` {r Investigation of 2015 raw citibike dataset}

###############################
#Now investigating the number of rows in all_data_2015
# Then, count the occurrences per date
daily_counts <- table(all_data_2015$starttime)

# To view the results
print(daily_counts)

#########Now investigating, if there are days without any booking#########
length_of_daily_counts <- length(daily_counts)
all_days_have_bookings <- length_of_daily_counts == 365

# Ausgabe
all_days_have_bookings
#Result: [1] TRUE


##########Now saving the 2015_citibike data in a CSV file
file_path <- "/Users/leonreiss/Desktop/DATA THESIS/Spatio temporal/final dataset/RawBikeData_2015.csv"

#Now saving dataframe as csv file
write.csv(all_data_2015, file_path, row.names = FALSE)

```

##Now checking if each csv file summed up has the same amount of rows compared to the all_data_2015 dataset

``` {r Investigation of 2015 raw citibike dataset, sum of rows is corresponding to the sum of rows for each csv in the folder}

# Set the main path to the directory containing subfolders for each month
main_path_2015 <- '/Users/leonreiss/Desktop/DATA THESIS/Spatio temporal/2015-citibike-tripdata'

# Get the list of all subfolder paths
month_folders <- list.files(main_path_2015, full.names = TRUE)

# Initialize a variable to store the total number of rows
total_rows <- 0

# Loop through each subfolder
for (month_folder in month_folders) {
    # List all CSV files within the current subfolder
    csv_files <- list.files(month_folder, pattern = '\\.csv$', full.names = TRUE)
    
    # Loop through each CSV file in the subfolder
    for (csv_file in csv_files) {
        # Read the number of lines in the current CSV file
        # Subtract 1 to exclude the header row
        num_rows_in_file <- length(readLines(csv_file)) - 1
        
        # Add the number of rows in the current CSV file to the total count
        total_rows <- total_rows + num_rows_in_file
    }
}

# Print the total number of rows from all CSV files
cat('Total number of rows across all CSV files:', total_rows, '\\n')

# Result: Total number of rows across all CSV files: 19875938 \n

##########Question: Why is it exactly the double amount in comparison to all_data_2015??

# Set the main path to the directories containing CSV files for each month
main_path_2015 <- '/Users/leonreiss/Desktop/DATA THESIS/Spatio temporal/2015-citibike-tripdata'

# List all subdirectories, which are named after months
month_folders <- list.files(main_path_2015, full.names = TRUE)

# Create an empty dataframe to store the results
csv_summary <- data.frame(filename = character(),
                          rows = integer(),
                          stringsAsFactors = FALSE)

# Loop through each month's folder
for (month_folder in month_folders) {
  # List all CSV files within the current month folder
  csv_files <- list.files(month_folder, pattern = "\\.csv$", full.names = TRUE)
  
  # Go through each CSV file and count the rows
  for (csv_file in csv_files) {
    # Count the number of rows, excluding the header row
    num_rows <- length(readLines(csv_file)) - 1
    
    # Append the file name and row count to the dataframe
    csv_summary <- rbind(csv_summary, data.frame(filename = csv_file, rows = num_rows))
  }
}

# Save the summary as a CSV file to the desktop
#write.csv(csv_summary, '/Users/leonreiss/Desktop/csv_summary.csv', row.names = FALSE)

# Print the dataframe containing file names and their respective row counts
print(csv_summary)


##Note/Result: the csv showed that the code scanned every csv file inside the main path twice. This is why the row sum of every csv is the doubled amount of all_data_2015

```
``` {r Investigation of 2015 raw citibike dataset for number of stations}

# Find unique station IDs in the 'start station id' column
unique_stations <- unique(all_data_2015$`start station id`)

# Count the number of unique stations
number_of_unique_stations <- length(unique_stations)

# Print the number of unique stations
print(paste("Number of unique stations in 'start station id':", number_of_unique_stations))

#Result: [1] "Number of unique stations in 'start station id': 488"

##########################

# Find unique station IDs in the 'end station id' column
unique_stations <- unique(all_data_2015$`end station id`)

# Count the number of unique stations
number_of_unique_stations <- length(unique_stations)

# Print the number of unique stations
print(paste("Number of unique stations in 'start station id':", number_of_unique_stations))
#[1] "Number of unique stations in 'start station id': 498"
all_data_2015 
```

## Weather Dataset 

```{r import and merge weather data, echo=FALSE}
# Set the path to the directory containing the weather CSV files
path_to_weather_data <- "/Users/leonreiss/Desktop/DATA THESIS/Weather"

# Construct the full paths to the individual CSV files
weather_data_2015_path <- file.path(path_to_weather_data, "new-york-2015.csv")
weather_data_2016_path <- file.path(path_to_weather_data, "new-york-2016.csv")

# Load the data from the CSV files
weather_data_2015 <- read.csv(weather_data_2015_path, stringsAsFactors = FALSE)
weather_data_2016 <- read.csv(weather_data_2016_path, stringsAsFactors = FALSE)

# Merge the weather data for 2015 and 2016, ensuring that 2015 is before 2016
csv_weather <- rbind(weather_data_2015, weather_data_2016)

# Check the result of the merge
head(weather_data_combined)

```

